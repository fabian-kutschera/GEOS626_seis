{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy.linalg import inv\n",
    "import numpy.matlib\n",
    "from scipy.stats.distributions import chi2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')                  # do not show warnings\n",
    "import scipy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python adaptation of genlsq.m written by Carl Tape\n",
    "# Applied Seismology, GEOS 626, University of Alaska Fairbanks\n",
    "# Python coding by Nealey Sims\n",
    "#\n",
    "# genlsq = Generalized Least Squares\n",
    "# Template script for the iterative quasi-Newton method for a 4-parameter\n",
    "# inversion for epicenter (xs, ys), origin time (ts), and velocity (V).\n",
    "# The algorithm employs generalized least squares, where by both data\n",
    "# covariances and model covariances are used.\n",
    "#\n",
    "# Background reading: Tarantola book (2005), Ch. 3 and Appendix 6.22\n",
    "#\n",
    "# calls forward_epicenter.ipynb, plot_covsamples\n",
    "#\n",
    "# Carl Tape, 2012-01-01\n",
    "#\n",
    "# Plotting parameter\n",
    "plt.rcParams['figure.figsize'] = 8, 8\n",
    "plt.rcParams['lines.linewidth'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================\n",
    "# USER INPUT\n",
    "\n",
    "nsamples = 1000;\n",
    "irandom_initial_model = 0;      # 0(fixed), 1(random)\n",
    "irandom_target_model = 0;       # 0(fixed), 1(random)\n",
    "idata_errors = 2;               # 0(none),  1(random), 2(fixed)\n",
    "ifig = 1;                       # 0,1\n",
    "\n",
    "#=========================================\n",
    "\n",
    "inormalization = 1;\n",
    "stnsamples = str(nsamples) + ' samples'\n",
    "stlabS = ('Sd(m^k)','Sm(m^k)','S(m^k) = Sd + Sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------\n",
    "# FORWARD PROBLEM    \n",
    "%run ./forward_epicenter.ipynb      # KEY COMMAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histo(hdat,edges,itype=2,make_plot=True):\n",
    "    #PLOT_HISTO plot a histogram with cyan bars and black boundaries\n",
    "    #\n",
    "    # INPUT\n",
    "    #   hdat        input data to bin\n",
    "    #   edges       vector defining the edges of the bins (for hdat)\n",
    "    #   itype       optional: type of histogram (=1,2,3) [default = 2]\n",
    "    #   make_plot   optional: plot histogram [default = true]\n",
    "    #hdat = hdat.flatten();\n",
    "    #barcolor = [1, 1, 1]*0.8;\n",
    "    \n",
    "    # bin width (only relevant if bins are the same width)\n",
    "    dbin = edges[1] - edges[0]\n",
    "    hedges=np.append(edges,edges[-1]+5)\n",
    "    Ntotal = len(hdat);\n",
    "    N,b = np.histogram(hdat,hedges);\n",
    "    if itype ==1:\n",
    "        Nplot = N; xlab = 'Count'\n",
    "    if itype ==2: \n",
    "        Nplot = np.divide(N,Ntotal); xlab = 'Fraction'\n",
    "    if itype ==3: \n",
    "        Nplot = np.divide(np.divide(N,Ntotal),dbin); xlab = 'PDF'\n",
    "        #if len(unique(edges)) > 1:\n",
    "        if np.std(np.diff(edges))/np.mean(np.diff(edges)) > 1e-4:       # ad hoc criterion\n",
    "            print(np.unique(np.diff(edges)))\n",
    "            print('PDF is not implemented to allow bins with varying widths')\n",
    "            \n",
    "    elif itype!=1 and itype!=2 and itype!=3: \n",
    "        print('itype = %i -- it must be 1,2, or 3'%(itype)) \n",
    "\n",
    "    if make_plot==True:\n",
    "        plt.bar(edges,Nplot, width=0.8*dbin);\n",
    "        plt.xlim([min(edges), max(edges)]);\n",
    "        plt.ylabel('%s (N=%i)'% (xlab,Ntotal))\n",
    "        \n",
    "        if len(hdat) != np.sum(N):\n",
    "            print('(plot_histo.m): You may want to extend the histogram edges -->');\n",
    "            print(' there are %i/%i input that are outside the specified range'%\n",
    "                (len(hdat)-np.sum(N),len(hdat)))\n",
    "            #disp(sprintf(' the number of input (%i) does not equal the sum of bin counts (%i).',length(hdat),sum(N)));\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predictions for prior and initial models (not necessary)\n",
    "dprior   = d(mprior)\n",
    "dinitial = d(minitial);\n",
    "\n",
    "if ifig==1:\n",
    "    # plot different histograms of properties of the prior model covariance samples\n",
    "    ##figure; nr=2; nc=2;\n",
    "    fig=plt.figure(figsize=(9,9))\n",
    "    for kk in range(nparm):\n",
    "        sigma = sigma_prior[kk]\n",
    "        #edges = [-4*sigma: sigma/2 : 4*sigma]\n",
    "        edges=np.arange(-4*sigma,4*sigma,sigma/2)\n",
    "        etemp = cov_samples_m[kk,:]\n",
    "        plt.subplot(2,2,kk+1)\n",
    "        plt.grid()\n",
    "        plot_histo(etemp,edges,2);\n",
    "        #plt.bar(etemp)\n",
    "        plt.ylim([0, 0.4])\n",
    "        plt.title('mprior samples: Model parameter '+str(kk+1)+' ('+str(mlabs[kk])+')\\n'+'mean = %.5f; std = %.5f' % (np.mean(etemp),np.std(etemp)))\n",
    "        plt.tight_layout()\n",
    "    # plot different histograms of properties of the data covariance samples\n",
    "    ##figure; nr=4; nc=3;\n",
    "    fig2 = plt.figure(figsize=(9,11))\n",
    "    for ii in range(ndata):\n",
    "        sigma = sigma_obs[ii];\n",
    "        edges=np.arange(-4*sigma,4*sigma,sigma/2)\n",
    "        etemp = cov_samples_d[ii,:]\n",
    "        plt.subplot(4,3,ii+1); \n",
    "        plot_histo(etemp,edges); \n",
    "        plt.ylim([0, 0.4]);\n",
    "        plt.title('Data index ' + str(ii+1) +'\\n'+'mean = %.5f; std = %.5f' % (np.mean(etemp),np.std(etemp))) \n",
    "        plt.tight_layout()\n",
    "    fig3 = plt.figure(figsize=(10,10))\n",
    "    plt.plot(dobs_samples,'.-');\n",
    "    p1 = plt.plot(dprior,'bo-',linewidth=2,markersize=10,markerfacecolor='b',markeredgecolor='w')\n",
    "    p2 = plt.plot(dinitial,'ko-',linewidth=2,markersize=10,markerfacecolor='k',markeredgecolor='w');\n",
    "    p3 = plt.plot(dtarget,'ro--',linewidth=2,markersize=10,markerfacecolor='r',markeredgecolor='w');\n",
    "    p4 = plt.plot(dobs,'ro-',linewidth=2,markersize=10,markerfacecolor='r',markeredgecolor='w');\n",
    "    plt.legend([p1[0], p2[0], p3[0], p4[0]],['g(mprior)','g(minitial)','g(mtarget)','g(mtarget) + errors',\n",
    "        'location','northwest'])\n",
    "    #title(' BLACK = d(mprior);  RED DASHED = d(mtarget);  RED = d(mtarget) + errors');\n",
    "    plt.xlim([0.5, ndata+0.5]); #set(gca,'xtick',[1:ndata]);\n",
    "    plt.xlabel('Data index'); plt.ylabel('Prediction value, g(m)');\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------\n",
    "# MISFIT FUNCTION : least squares, Tarantola (2005), Eq. 6.251\n",
    "# (This calls the function d to compute the predictions.)\n",
    "\n",
    "# data misfit\n",
    "def Sd(m,dobs,icobs):\n",
    "    sd=((np.dot(0.5,(d(m)-dobs).T))@icobs)@(d(m)-dobs)\n",
    "    return sd\n",
    "# model misfit (related to regularization)\n",
    "def Sm(m,mprior,icprior):\n",
    "    sm=((np.dot(0.5,(m-mprior).T))@icprior)@(m-mprior)\n",
    "    return sm\n",
    "# total misfit\n",
    "def S(m,dobs,mprior,icobs,icprior):\n",
    "    s=Sd(m,dobs,icobs) + Sm(m,mprior,icprior)\n",
    "    return s\n",
    "\n",
    "# initial model\n",
    "#mnew = mprior;     # prior model\n",
    "#mnew = mtarget;       # target model\n",
    "mnew = minitial;\n",
    "mnew=mtarget\n",
    "Sd_0 = Sd(mnew,dobs,icobs);\n",
    "Sm_0 = Sm(mnew,mprior,icprior);\n",
    "S_0  = S(mnew,dobs,mprior,icobs,icprior);\n",
    "stS0 = ' S(m0) = %.3f = %.3f(D) + %.3f(M)'% (S_0,Sd_0,Sm_0)\n",
    "print(stS0);\n",
    "\n",
    "niter = input(' Select the number of iterations (< 10) or 0 to exit: ');\n",
    "if int(niter)==0:\n",
    "    print('0 iterations selected. exiting...')\n",
    "    #quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if int(niter) !=0:\n",
    "    # initialize arrays\n",
    "    niter=int(niter)\n",
    "    iter_vec = np.transpose(np.arange(0,niter))\n",
    "    Sd_vec = np.zeros((niter,1));\n",
    "    Sm_vec = np.zeros((niter,1));\n",
    "    S_vec = np.zeros((niter,1));\n",
    "    \n",
    "    # misfit for initial model\n",
    "    Sd_vec[0] = Sd_0;\n",
    "    Sm_vec[0] = Sm_0;\n",
    "    S_vec[0] = S_0;\n",
    "    \n",
    "    for nn in range(niter):\n",
    "        #///////////////////////////////\n",
    "        #print('CODE HERE for quasi-Newton algorithm')\n",
    "        print(' ')\n",
    "        \n",
    "        \n",
    "        # fill misfit function S_vec, Sd_vec, Sm_vec for plotting later\n",
    "        #Sd_vec(nn+1) = \n",
    "        #Sm_vec(nn+1) = \n",
    "        #S_vec(nn+1) = \n",
    "        \n",
    "        #///////////////////////////////\n",
    "        \n",
    "    # misfit function values\n",
    "    print('summary of misfit function:');\n",
    "    print('%8s%16s%16s%16s'% ('iter','Sd','Sm','S = Sm + Sd'))\n",
    "    for nn in range(niter):\n",
    "        print('%8i%16.10f%16.10f%16.10f' % (iter_vec[nn],Sd_vec[nn],Sm_vec[nn],S_vec[nn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if int(niter) !=0:\n",
    "    if ifig==1:\n",
    "        # plot convergence curve\n",
    "        ylims = [10**-2, 10**2];\n",
    "        stit = str(niter) +' iterations'\n",
    "        plt.plot(iter_vec, np.log10(Sd_vec),'r.-',iter_vec, np.log10(Sm_vec),'b.-',iter_vec, np.log10(S_vec),'k.-',\n",
    "            linewidth=2,markersize=20)\n",
    "        plt.legend(stlabS); plt.xlim([-0.5, niter+0.5]); plt.ylim(np.log10(ylims))\n",
    "        plt.locator_params(axis=\"x\", integer=True, tight=True)\n",
    "        plt.xlabel('k, iteration'); plt.ylabel(' log10[ S(m^k) ], misfit function'); plt.title(stit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if int(niter) !=0:\n",
    "    def corrcov(cov):\n",
    "        # convert correlation matrix from covariance matrix\n",
    "        v = np.sqrt(np.diag(cov))\n",
    "        outer_v = np.outer(v, v)\n",
    "        corr = cov / outer_v\n",
    "        corr[cov == 0] = 0\n",
    "        return corr\n",
    "    \n",
    "    #///////////////////////////////\n",
    "    # COMPUTE THE FOLLOWING\n",
    "    # mpost       posterior model (\"final\" model)\n",
    "    # dpost       predictions for mpost\n",
    "    # Gpost       partial derivatives matrix at mpost\n",
    "    # cpost0      posterior covariance matrix (use icobs0 and icprior0)\n",
    "    # sigma_post  variances of the posterior covariance matrix\n",
    "    # rho_post    posterior correlation matrix (hint: see Tarantola, Section 3.3)\n",
    "    # CODE HERE\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #///////////////////////////////\n",
    "    #    \n",
    "    # a priori model correlations (for comparison)\n",
    "\n",
    "    rho_prior = corrcov(cprior0)\n",
    "    \n",
    "    print('cpost0 \\n', cpost0, '\\n', 'rho_post \\n', rho_post)\n",
    "    \n",
    "    # posterior data covariance matrix (e.g., Tarantola Eq. 3.44)\n",
    "    \n",
    "    cpost0_d = Gpost@cpost0@Gpost.T\n",
    "    cpost0_d = (cpost0_d + cpost0_d.T)/2       # force to be symmetric\n",
    "    sigma_post_d = np.sqrt(np.diag(cpost0_d))  # IGNORING OFF-DIAGONAL ELEMENTS\n",
    "    rho_post_d = corrcov(cpost0_d)             # posterior correlation matrix\n",
    "    rho_prior_d = corrcov(cobs0)               # prior, for comparison\n",
    "    \n",
    "    #format long\n",
    "    print('model summary (%i iterations):'% (niter))\n",
    "    print('%16s%16s%16s%16s' % ('prior', 'initial','posterior', 'target'))\n",
    "    for ii in range(len(mprior)):\n",
    "            print('%16s%16s%16s%16s'%(str(mprior[ii]),str(minitial[ii]),str(mpost[ii]), str(mtarget[ii])))\n",
    "    print('data summary (%i observations):' % (ndata))\n",
    "    print('%16s%16s%16s%16s%16s'% ('prior', 'initial','posterior', 'target', 'actual'))\n",
    "    for ii in range(len(mprior)):\n",
    "            print('%16s%16s%16s%16s%16s'%(str(dprior[ii]),str(dinitial[ii]),str(dpost[ii]), \n",
    "                                          str(dtarget[ii]), str(dobs[ii])))\n",
    "    # Cholesky decomposition to obtain the square-root of cpost0\n",
    "    # NOTE: for large problems, this is not possible due to poor\n",
    "    #       conditioning of cpost0 or the inability to compute cpost0\n",
    "    Lpost = np.linalg.cholesky(cpost0);\n",
    "    \n",
    "    # samples of the posterior distribution\n",
    "    mpost_samples = np.zeros((nparm,nsamples))\n",
    "    mcov_samples = np.zeros((nparm,nsamples))\n",
    "    for xx in range(nsamples): \n",
    "        randn_vecs_m[:,xx] = np.random.randn(nparm)\n",
    "    mcov_samples  = Lpost @ randn_vecs_m;\n",
    "    mpost_samples = np.matlib.repmat(mpost,1,nsamples) + mcov_samples;\n",
    "    \n",
    "    # compare the standard deviation with sigma_post\n",
    "    \n",
    "    std_samples = np.std(mpost_samples.T, axis=0);\n",
    "                 \n",
    "    # compare posterior model distribution with prior\n",
    "    # note: format statement allows for vectors (like sigma_prior)\n",
    "    print('  ');\n",
    "    print(' Compare model uncertainties : ');\n",
    "    print('             model parameter : %13s%13s%13s%13s' %(mlabs[0],mlabs[1],mlabs[2],mlabs[3]))\n",
    "    print('                       units : %13s%13s%13s%13s' %(ulabs[0],ulabs[1],ulabs[2],ulabs[3]));\n",
    "    print('                 sigma_prior = %13.5s%13.5s%13.5s%13.5s'%(sigma_prior[0],sigma_prior[1],\n",
    "                                                                     sigma_prior[2],sigma_prior[3]))\n",
    "    print('                  sigma_post = %13.5s%13.5s%13.5s%13.5s'%(sigma_post[0],sigma_post[1],\n",
    "                                                                     sigma_post[2],sigma_post[3]));\n",
    "    print('   std(%6.0f mpost_samples) = %13.5s%13.5s%13.5s%13.5s' % (nsamples, std_samples[0],std_samples[1],\n",
    "                                                                      std_samples[2],std_samples[3]));\n",
    "    print('    sigma_post / sigma_prior = %13.5s%13.5s%13.5s%13.5s' % (np.divide(sigma_post[0],sigma_prior[0]),\n",
    "                                                                      np.divide(sigma_post[1],sigma_prior[1]),\n",
    "                                                                      np.divide(sigma_post[2],sigma_prior[2]),\n",
    "                                                                      np.divide(sigma_post[3],sigma_prior[3])));\n",
    "    print('1 - sigma_post / sigma_prior = %13.5s%13.5s%13.5s%13.5s' % (1 - np.divide(sigma_post[0],sigma_prior[0]),\n",
    "                                                                      1 - np.divide(sigma_post[1],sigma_prior[1]),\n",
    "                                                                      1 - np.divide(sigma_post[2],sigma_prior[2]),\n",
    "                                                                      1 - np.divide(sigma_post[3],sigma_prior[3])))\n",
    "    print('  ')              \n",
    "                  \n",
    "    # compute the predictions associated with the posterior samples,\n",
    "    # then compare std_d_samples with sigma_post_d\n",
    "    d_samples = np.zeros((ndata,nsamples))\n",
    "    for xx in range(nsamples):\n",
    "        ms = mpost_samples[:,xx]\n",
    "        d_samples[:,xx] = d(ms)\n",
    "    \n",
    "    covd_samples = np.cov(d_samples)\n",
    "    rhod_samples = corrcov(covd_samples)\n",
    "    std_d_samples = np.sqrt(np.diag(covd_samples))\n",
    "    #std_d_samples = std(d_samples');\n",
    "    \n",
    "    \n",
    "    print('  ');\n",
    "    print(' Compare data uncertainties : ')\n",
    "    print('%16s %10s %10s %10s'%('prior','post','samples','post/prior'))\n",
    "    call = [sigma_obs, sigma_post_d, std_d_samples, np.divide(sigma_post_d,sigma_obs)];\n",
    "    for ii in range(ndata):\n",
    "        print('%6i%10.4f %10.4f %10.4f %10.4f'%(ii,call[0][ii],call[1][ii],call[2][ii],call[3][ii]))\n",
    "    print('  ');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_covsamples(msamples,rho,tlab,msamples2,rho2,tlab2,mlabs):\n",
    "    # Python adaptation of plot_covsamples\n",
    "    #PLOT_COVMSAMPLES generates plots for samples of covariance matrix\n",
    "    #\n",
    "    # INPUT\n",
    "    #    msamples   n x s matrix of vector samples\n",
    "    #    rho        n x n 'analytical' correlation matrix\n",
    "    #    tlab       label for plot\n",
    "    #    msamples2  optional: 2nd set of samples ([] for none)\n",
    "    #    rho2       optional: 2nd 'analytical' correlation matrix ([] for none)\n",
    "    #    tlab2      optional: label for plot\n",
    "    #    mlabs      optional: labels for each variable ([] for default)\n",
    "    #\n",
    "    # EXAMPLE: \n",
    "    #    plot_covsamples(mpost_samples,rho_post,'mpost',[],[],[],mlabs);\n",
    "    #\n",
    "    # NOTE: We could alternatively estimate the covariance matrix\n",
    "    # (and correlation matrix) directly from the input samples.\n",
    "    #\n",
    "    #\n",
    "    # Carl Tape, 2012-01-01\n",
    "    #\n",
    "    NMAX = 6;   # max number to make into scatterplot\n",
    "    \n",
    "    n = np.shape(msamples)[0]; s = np.shape(msamples)[1]\n",
    "    print('plot_covsamples: n = %i, s = %i'%(n,s))\n",
    "    \n",
    "    if len(mlabs)==0:\n",
    "        #mlabs = strtrim(cellstr(num2str([1:n]')));\n",
    "        mlabs = np.matlib.repmat(str(''),n,1);\n",
    "        for ii in range(n):\n",
    "            mlabs[ii] = 'i%i'%(ii)\n",
    "\n",
    "    # whether to plot a second set of samples\n",
    "    if len(msamples2)!=0 and len(rho2)!=0:\n",
    "        isecond = 1; \n",
    "    else:\n",
    "        isecond = 0\n",
    "    \n",
    "    # kk=1: correlation matrices from Cpost\n",
    "    # kk=2: correlation matrices based on input SAMPLES\n",
    "    fig=plt.figure(figsize=(8,8)); \n",
    "    nr=1+isecond; nc=2;\n",
    "    for kk in [0,1]:\n",
    "        if kk==0:\n",
    "            F1 = rho; \n",
    "            if isecond==1:\n",
    "                F2 = rho2\n",
    "            stag = ''\n",
    "        else:\n",
    "            F1 = np.corrcoef(msamples);\n",
    "            if isecond==2:\n",
    "                F2 = np.corrcoef(msamples2)\n",
    "            stag = 'sample'\n",
    "        pind = kk+1+isecond*(kk);\n",
    "        plt.subplot(nr,nc,pind) \n",
    "        plt.imshow(F1,cmap='jet', vmin=-1,vmax=1);\n",
    "        if isecond==0:\n",
    "            plt.colorbar(shrink=0.35, aspect=10)\n",
    "        else:\n",
    "            plt.colorbar(shrink=0.8, aspect=10)\n",
    "        #caxis([-1 1]), colorbar\n",
    "        #set(gca,'xtick',[1:n],'xticklabel',mlabs,'xaxislocation','top');\n",
    "        #set(gca,'ytick',[1:n],'yticklabel',mlabs);\n",
    "        plt.title(str(stag)+ ' correlation matrix for '+ str(tlab));\n",
    "        #axis equal, axis tight\n",
    "        \n",
    "        if isecond==1:\n",
    "            plt.subplot(nr,nc,pind+1); \n",
    "            plt.imshow(F2, cmap='jet', vmin=-1,vmax=1); #caxis([-1 1]), colorbar\n",
    "            #set(gca,'xtick',[1:n],'xticklabel',mlabs,'xaxislocation','top');\n",
    "            #set(gca,'ytick',[1:n],'yticklabel',mlabs);\n",
    "            plt.title(str(stag)+ ' correlation matrix for '+ str(tlab2));\n",
    "            plt.colorbar(shrink=0.8, aspect=10)\n",
    "            #axis equal, axis tight\n",
    "\n",
    "    # scatterplots\n",
    "    if n > NMAX:\n",
    "        print('n = %i is > %i, so no scatterplots made'% (n,NMAX))\n",
    "    else:\n",
    "        fig=plt.figure(figsize=(8,8)); \n",
    "        nr=n-1; nc=n-1;\n",
    "        for ii in range(n-1):\n",
    "            jj=ii+1\n",
    "            while jj<n: \n",
    "                px = np.array([msamples[ii,:]])\n",
    "                py = np.array([msamples[jj,:]])\n",
    "                iplot = nc*(ii) + jj;\n",
    "                #disp([ii jj iplot]);\n",
    "                plt.subplot(nr,nc,iplot);\n",
    "                plt.plot(px,py,'b.',markersize=2);\n",
    "                plt.xlabel(mlabs[ii]); plt.ylabel(mlabs[jj]);\n",
    "                st1 = 'corr(%s) = %.2f (%.2f)'% (tlab,np.corrcoef(px,py,ddof=0)[0,1],rho[ii,jj]);\n",
    "                if isecond==1:\n",
    "                    px = msamples2[ii,:]\n",
    "                    py = msamples2[jj,:]\n",
    "                    plt.plot(px,py,'r.',markersize=2);\n",
    "                    st2 = 'corr(%s) = %.2f (%.2f)'% (tlab2,np.corrcoef(px,py,ddof=0)[0,1],rho2[ii,jj])\n",
    "                    plt.title(str(st1)+'\\n'+ str(st2));\n",
    "                else:\n",
    "                    plt.title(str(st1));\n",
    "                jj+=1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if int(niter) !=0:\n",
    "    if ifig==1:\n",
    "        # display distributions for each model parameter (nparm ROWS of cov_samples_m)\n",
    "        fig=plt.figure(figsize=(8,8));\n",
    "        nr=2; nc=2;\n",
    "        for kk in range(nparm):\n",
    "            sigma = sigma_post[kk];\n",
    "            edges=np.arange(-4*sigma,4*sigma,sigma/2)\n",
    "            etemp = mcov_samples[kk,:]\n",
    "            plt.subplot(nr,nc,kk+1); \n",
    "            plot_histo(etemp,edges); \n",
    "            plt.ylim([0, 0.4]); \n",
    "            plt.grid\n",
    "            stl1 = 'mpost samples'\n",
    "            stl2 = 'Model parameter ' +str(kk) +' (' +str(mlabs[kk]) +')'\n",
    "            stl3 = 'mean = %.5f; std = %.5f' % (np.mean(etemp),np.std(etemp))\n",
    "            \n",
    "            if kk==1: \n",
    "                plt.title(str(stl1)+str(stl2)+'\\n'+str(stl3))\n",
    "            else: \n",
    "                plt.title(str(stl2)+'\\n'+str(stl3))\n",
    "        plt.tight_layout()\n",
    "        # correlation matrices and scatterplots\n",
    "        #plot_covsamples(mprior_samples,rho_prior,'mprior',[],[],[],mlabs);\n",
    "        plot_covsamples(mpost_samples,rho_post,'mpost',[],[],[],mlabs);\n",
    "        plot_covsamples(mprior_samples,rho_prior,'mprior',mpost_samples,rho_post,'mpost',mlabs);\n",
    "        \n",
    "        # 'physical view' of estimated posterior data uncertainties\n",
    "        # note: plot either sigma_post_d (from Cpost_d) or std_d_samples (from d(Cpost_samples))\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.subplot(aspect=1)\n",
    "        plt.plot(mpost_samples[0,:],mpost_samples[1,:],'c.');\n",
    "        plt.plot(mpost[0],mpost[1],'o',markersize=10,markerfacecolor='c',markeredgecolor='w');\n",
    "        #plot(mprior(1),mprior(2),'o','markersize',10,'markerfacecolor','b','markeredgecolor','w');\n",
    "        #scatter(xrec,yrec,16^2,sigma_post_d,'filled','V'); title('estimated uncertainties for posterior predictions');\n",
    "        \n",
    "        plt.scatter(xrec,yrec,16**2,std_d_samples,marker='v',edgecolors='k', cmap='hot'); \n",
    "        #plt.scatter(xrec,yrec,16**2,'k',marker='v', cmap='hot');\n",
    "        plt.xlim([0,100]);plt.ylim([0,100])\n",
    "        #set(gca,'xtick',[0:20:100],'ytick',[0:20:100]);\n",
    "        plt.xlabel('X distance (km)'); plt.ylabel('Y distance (km)');\n",
    "        plt.colorbar(shrink=0.8);\n",
    "        plt.title('uncertainties for posterior predictions, computed from samples');\n",
    "        plt.show()\n",
    "        # plot predictions for samples of the posterior\n",
    "        plot_covsamples(d_samples,rho_post_d,'dpost',[],[],[],[]);\n",
    "        \n",
    "        #plt.subplot(aspect=1)\n",
    "        # note: opts is set in forward_epicenter\n",
    "        plot_epicenters(mprior_samples,mprior,minitial,mtarget,opts,mpost);\n",
    "        # plot the cpost0 samples and re-plot the two markers\n",
    "        plt.plot(mpost_samples[0,:],mpost_samples[1,:],'c.')\n",
    "        plt.plot(mpost[0],mpost[1],'o',markersize=10,markerfacecolor='c',markeredgecolor='w')\n",
    "        plt.plot(mtarget[0],mtarget[1],'o',markersize=10,markerfacecolor='r',markeredgecolor='w')\n",
    "        plt.plot(minitial[0],minitial[1],'o',markersize=10,markerfacecolor='k',markeredgecolor='w')\n",
    "        plt.xlim([0,100]);plt.ylim([0,100]);plt.axis('equal')\n",
    "        plt.title('samples of prior (blue) and posterior (cyan)');\n",
    "        plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
